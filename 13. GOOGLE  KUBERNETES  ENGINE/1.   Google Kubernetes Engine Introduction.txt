
Google Kubernetes Engine:
==========================

1. GKE overview:
=================

. Google Kubernetes Engine (GKE) provides a managed environment for deploying, managing, and scaling your containerized applications 
  using Google infrastructure. 
. The GKE environment consists of multiple machines (specifically, Compute Engine instances) grouped together to form a cluster.


2. Cluster orchestration with GKE:
==================================

. GKE clusters are powered by the Kubernetes open source cluster management system.
. Kubernetes provides the mechanisms through which you interact with your cluster.
. You use Kubernetes commands and resources to deploy and manage your applications, 
  perform administration tasks, set policies, and monitor the health of your deployed workloads.


3. Kubernetes on Google Cloud :
================================
. When you run a GKE cluster, you also gain the benefit of advanced cluster management features that Google Cloud provides. These include:

- Google Cloud's load-balancing for Compute Engine instances
- Node pools to designate subsets of nodes within a cluster for additional flexibility
- Automatic scaling of your cluster's node instance count
- Automatic upgrades for your cluster's node software
- Node auto-repair to maintain node health and availability
- Logging and monitoring with Google Cloud's operations suite for visibility into your cluster


4. Kubernetes versions and features:
======================================
. GKE cluster control planes are automatically upgraded to run new versions of Kubernetes as those versions become stable,
  so you can take advantage of newer features from the open source Kubernetes project.



5. GKE workloads:
==================
. GKE works with containerized applications. These are applications packaged into platform independent, isolated user space instances, 
  for example by using Docker.
. In GKE and Kubernetes, these containers, whether for applications or batch jobs, are collectively called workloads. 
. Before you deploy a workload on a GKE cluster, you must first package the workload into a container.


. GKE supports the use of container images that are built with Docker, for example as part of a build and deploy pipeline. 
. In GKE version 1.24 and later, Docker cannot manage the lifecycle of containers running on GKE nodes.

. Google Cloud provides continuous integration and continuous delivery tools to help you build and serve application containers. 
  You can use Cloud Build to build container images (such as Docker) from a variety of source code repositories, and 
  Artifact Registry or Container Registry to store and serve your container images.
  
  
 
6. Modes of operation:
=======================
. GKE clusters have two modes of operation to choose from:

1. Autopilot: 
-------------
. Manages the entire cluster and node infrastructure for you. 
. Autopilot provides a hands-off Kubernetes experience so that you can focus on your workloads and only pay for the resources required 
  to run your applications. 
. Autopilot clusters are pre-configured with an optimized cluster configuration that is ready for production workloads.


2. Standard: 
-------------
. Provides you with node configuration flexibility and full control over managing your clusters and node infrastructure. 
. For clusters created using the Standard mode, you determine the configurations needed for your production workloads, 
  and you pay for the nodes that you use.

































